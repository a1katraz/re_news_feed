{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3f1de8-efd6-45fe-b640-7e0927e44f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv as env\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import pandas\n",
    "import pprint as pp\n",
    "import sys\n",
    "\n",
    "env.load_dotenv('../keys/keys.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7d8e05-fc66-47cc-bf5d-8837d9859e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadlineClassification(BaseModel):\n",
    "    title: str                          #Do not change the name of this field as OpenAI is dumb. If you keep it as inputs, then only it returns the original text sent to it.\n",
    "                                        # Will have to carefully write wrappers to ensure that the outcome df to be used in the final output has the right headers. \n",
    "    classification: bool\n",
    "    explanation: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0bf6198-84ba-4370-b672-b0af3d9936ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class listClassifications(BaseModel):\n",
    "    output: list[HeadlineClassification]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d75f65a-169a-4642-9cdf-a73df3b125ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAIModels:\n",
    "    #__client: \n",
    "    #__model_name = 'gpt-4.1-nano-2025-04-14'\n",
    "    __model_name = 'gpt-4o-mini-2024-07-18'          #produces most realiable output\n",
    "    #__model_name = 'o4-mini-2025-04-16'\n",
    "    __prompt_file_path = '../prompts/open_ai_prompts.json'\n",
    "\n",
    "    def __init__(self):\n",
    "        #self.__model_name = 'gpt-4.1-nano-2025-04-14'\n",
    "        #self.__prompt_file_path = '../prompts/open_ai_prompts.json'\n",
    "        self.__client = OpenAI(api_key=os.environ.get('OPENAI_API_KEY'))\n",
    "    \n",
    "    def __getPromptFromFile(self, type: str) -> str:\n",
    "        with open(OpenAIModels.__prompt_file_path, 'r') as file:\n",
    "            data = file.read()\n",
    "        parsed_data = json.loads(data)\n",
    "        prompt = parsed_data.get(type)\n",
    "        return prompt\n",
    "\n",
    "    def classify_headlines(self, input: pandas.DataFrame, silent_mode=True) -> str :\n",
    "        if(silent_mode):\n",
    "            original_stdout = sys.stdout   # save the original stdout\n",
    "            sys.stdout = open(os.devnull, 'w')\n",
    "        prompt = self.__getPromptFromFile('headlines_classifier_real_estate') \n",
    "        #print(prompt)\n",
    "        print('Sending titles for classification to OpenAI model...')\n",
    "        print(f'Input is of length: {len(input)}.')\n",
    "        try:\n",
    "            response = self.__client.responses.parse(\n",
    "                        model=OpenAIModels.__model_name,\n",
    "                        #service_tier='default',\n",
    "                        temperature=0.8,\n",
    "                        instructions=prompt, \n",
    "                        input=input.to_json(orient='records'),\n",
    "                        text_format=listClassifications\n",
    "                    )\n",
    "            return response.output_text\n",
    "        except Exception as e:\n",
    "            print(f'Open AI execution threw an exception: {e}')\n",
    "            return None\n",
    "        finally:\n",
    "            if(silent_mode):\n",
    "                sys.stdout.close()\n",
    "                sys.stdout = original_stdout    #restore the original stdout, other wise it will fail other prints.\n",
    "            #Since the textformat here is a class wrapper of lists\n",
    "            # So the return response must be handled to strip the 'output' dictionary to get to the inner lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb697c9b-be08-48aa-a186-19855b8cd808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one line tester\n",
    "\n",
    "#llm = OpenAIModels()\n",
    "#df = pandas.DataFrame([['Mumbai', 'Ghatkopar college student among two to drown i...'], \n",
    "#                       ['Mumbai', 'NCP-SP MLA Jitendra Awhad receives death threats'], \n",
    "#                       ['Mumbai', 'Mumbai court says life term for rapist dad too']], \n",
    "#                      columns=['sub-site', 'title'])\n",
    "#response = llm.classify_headlines(df[['sub-site', 'title']], silent_mode=False)\n",
    "#out_df = pandas.DataFrame(json.loads(response)['output'], columns=['title', 'classification', 'explanation'])\n",
    "#out_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
