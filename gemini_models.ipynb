{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98464ebb-3904-48c4-b9a0-8f56588b69dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "import pprint as pp\n",
    "import dotenv as env\n",
    "import sys\n",
    "import pandas\n",
    "env.load_dotenv('../keys/keys.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e111981-e136-45b0-85b2-9954e3613fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadlineClassification(BaseModel):\n",
    "    link_id: str\n",
    "    title: str                          #Do not change the name of this field as OpenAI is dumb. If you keep it as inputs, then only it returns the original text sent to it.\n",
    "                                        # Will have to carefully write wrappers to ensure that the outcome df to be used in the final output has the right headers. \n",
    "    classification: bool\n",
    "    explanation: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "becf0a3e-1eeb-43d5-b73c-302a488708cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gemini_Models:\n",
    "    __model_name = 'gemini-2.5-pro-exp-03-25'          #produces most realiable output\n",
    "    #__model_name = 'o4-mini-2025-04-16'\n",
    "    __prompt_file_path = '../prompts/gemini_ai_prompts.json'\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\")) \n",
    "        \n",
    "    def __getPromptFromFile(self, type: str) -> str:\n",
    "        with open(Gemini_Models.__prompt_file_path, 'r') as file:\n",
    "            data = file.read()\n",
    "        parsed_data = json.loads(data)\n",
    "        prompt = parsed_data.get(type)\n",
    "        return prompt\n",
    "    \n",
    "    def classify_headlines(self, input: pandas.DataFrame, silent_mode=True) -> str:\n",
    "        if(silent_mode):\n",
    "            original_stdout = sys.stdout   # save the original stdout\n",
    "            sys.stdout = open(os.devnull, 'w')\n",
    "        prompt = self.__getPromptFromFile('headlines_classifier_real_estate') \n",
    "        #print(prompt)\n",
    "        print('Sending titles for classification to Gemini model...')\n",
    "        print(f'Input is of length: {len(input)}.')\n",
    "        generation_config = types.GenerateContentConfig(\n",
    "                                temperature=0.8,\n",
    "                                #response_mime_type=\"text/plain\", # for simpler use cases where only text is expected from the model \n",
    "                                system_instruction=[\n",
    "                                                    types.Part.from_text(text=prompt),\n",
    "                                                    ],\n",
    "                                response_mime_type='application/json',\n",
    "                                response_schema=list[HeadlineClassification],    #force response in a structured format from Gemini\n",
    "                            )\n",
    "        contents = [types.Content(\n",
    "                        role=\"user\",\n",
    "                        parts=[\n",
    "                                types.Part.from_text(text=input.to_json(orient='records')),    \n",
    "                            ],\n",
    "                        ),\n",
    "                    ]\n",
    "    \n",
    "        try:\n",
    "            model_reply = self.__client.models.generate_content(model=self.__model_name, contents=contents, config=generation_config)\n",
    "            return model_reply.text\n",
    "        except Exception as e:\n",
    "            print(f'Gemini AI execution threw an exception: {e}')\n",
    "            return None\n",
    "        finally:\n",
    "            if(silent_mode):\n",
    "                sys.stdout.close()\n",
    "                sys.stdout = original_stdout\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3507ee94-4e66-4735-81a7-2b6576c5f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One line tester\n",
    "\n",
    "#llm = Gemini_Models()\n",
    "#df = pandas.DataFrame([['Mumbai', 'Ghatkopar college student among two to drown i...'], \n",
    "#                       ['Mumbai', 'NCP-SP MLA Jitendra Awhad receives death threats'], \n",
    "#                       ['Mumbai', 'Mumbai court says life term for rapist dad too']], \n",
    "#                      columns=['sub-site', 'title'])\n",
    "#response = llm.classify_headlines(df[['sub-site', 'title']], silent_mode=False)\n",
    "#out_df = pandas.DataFrame(json.loads(response), columns=['title', 'classification', 'explanation'])\n",
    "#out_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
